# DataReady.io

**AI-Powered Data Engineering Mock Interview Platform**

A production-ready platform for simulating realistic data engineering interviews with adaptive AI, role-based difficulty, and comprehensive feedback.

![DataReady.io](https://img.shields.io/badge/version-0.1.0-blue)
![Python](https://img.shields.io/badge/python-3.12+-green)
![License](https://img.shields.io/badge/license-MIT-blue)

---

## ğŸ¯ Features

### Interview Experience
- **Adaptive AI Interviewer** - Adjusts questions based on your performance
- **Role-Based Difficulty** - Junior to Principal-level interviews
- **Live Audio Interaction** - Respond verbally, hear questions spoken
- **Real-Time Transcription** - See your responses as you speak
- **Follow-Up Questions** - Dynamic probing based on answer depth

### Skill Assessment
- **10+ Skill Categories** - SQL, Spark, Streaming, System Design, etc.
- **Cloud-Specific Options** - AWS, GCP, Azure, or cloud-agnostic
- **Performance Tracking** - Difficulty adapts in real-time

### Feedback & Reporting
- **Detailed Score Breakdown** - 5 evaluation dimensions
- **Skill-Wise Analysis** - Radar chart visualization
- **Hiring Verdict** - Strong Hire to Needs Improvement
- **Personalized Study Roadmap** - Week-by-week improvement plan

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (HTML/CSS/JS)                       â”‚
â”‚  Setup Page â†’ Interview Room â†’ Report Dashboard                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚ WebSocket + REST API
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   BACKEND (Python FastAPI)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Interview Orchestrator â”€â”¬â”€ AI Reasoning Layer (Gemini)         â”‚
â”‚                          â”œâ”€ Audio Processing (Whisper/TTS)      â”‚
â”‚                          â”œâ”€ Evaluation Engine                   â”‚
â”‚                          â””â”€ Report Generator                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.12+
- [uv](https://docs.astral.sh/uv/) (Python package manager)
- Databricks account with Gemini model access
- Microphone and webcam (for interview)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/KaushalVachhani/DataReady.io.git
   cd DataReady.io
   ```

2. **Install uv** (if not already installed)
   ```bash
   # macOS/Linux
   curl -LsSf https://astral.sh/uv/install.sh | sh
   
   # Windows
   powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
   ```

3. **Install dependencies**
   ```bash
   uv sync
   ```

4. **Configure environment**
   ```bash
   cp .env.example .env
   # Edit .env with your Databricks credentials
   ```

5. **Run the server**
   ```bash
   uv run python main.py
   ```

6. **Open in browser**
   ```
   http://localhost:8000
   ```

### Docker (Alternative)

```bash
# Build the image
docker build -t dataready .

# Run the container
docker run -p 8000:8000 --env-file .env dataready
```

---

## ğŸ“ Project Structure

```
dataready-io/
â”œâ”€â”€ main.py                 # FastAPI application entry point
â”œâ”€â”€ pyproject.toml          # Project dependencies
â”œâ”€â”€ .env.example            # Environment configuration template
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                # REST & WebSocket endpoints
â”‚   â”‚   â”œâ”€â”€ endpoints/      # Route handlers
â”‚   â”‚   â”œâ”€â”€ router.py       # Main API router
â”‚   â”‚   â””â”€â”€ dependencies.py # Dependency injection
â”‚   â”‚
â”‚   â”œâ”€â”€ core/               # Business logic
â”‚   â”‚   â”œâ”€â”€ interview_orchestrator.py  # State machine
â”‚   â”‚   â”œâ”€â”€ ai_reasoning.py            # Gemini integration
â”‚   â”‚   â”œâ”€â”€ audio_processor.py         # STT/TTS
â”‚   â”‚   â”œâ”€â”€ evaluation_engine.py       # Scoring
â”‚   â”‚   â””â”€â”€ report_generator.py        # Report creation
â”‚   â”‚
â”‚   â”œâ”€â”€ models/             # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ interview.py    # Session & state
â”‚   â”‚   â”œâ”€â”€ question.py     # Questions
â”‚   â”‚   â”œâ”€â”€ evaluation.py   # Scoring
â”‚   â”‚   â”œâ”€â”€ report.py       # Report structure
â”‚   â”‚   â””â”€â”€ roles.py        # Roles & skills
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts/            # AI prompt templates
â”‚   â”‚   â”œâ”€â”€ interviewer.py  # Question generation
â”‚   â”‚   â”œâ”€â”€ evaluator.py    # Response evaluation
â”‚   â”‚   â””â”€â”€ report.py       # Report generation
â”‚   â”‚
â”‚   â””â”€â”€ config/             # Configuration
â”‚       â””â”€â”€ settings.py     # Environment settings
â”‚
â”œâ”€â”€ static/                 # Frontend assets
â”‚   â”œâ”€â”€ index.html          # Setup page
â”‚   â”œâ”€â”€ interview.html      # Interview room
â”‚   â”œâ”€â”€ report.html         # Report dashboard
â”‚   â”œâ”€â”€ css/styles.css      # Styles
â”‚   â””â”€â”€ js/                 # JavaScript
â”‚       â”œâ”€â”€ setup.js
â”‚       â”œâ”€â”€ interview.js
â”‚       â””â”€â”€ report.js
â”‚
â””â”€â”€ docs/
    â””â”€â”€ ARCHITECTURE.md     # System design documentation
```

---

## ğŸ“ Role Definitions

| Role | Experience | Focus Areas |
|------|------------|-------------|
| **Junior DE** | 0-2 years | SQL, ETL basics, Git, Cloud fundamentals |
| **Mid-Level DE** | 2-5 years | Advanced SQL, Spark, Orchestration, Data quality |
| **Senior DE** | 5-8 years | Platform design, Performance, Streaming |
| **Staff DE** | 8+ years | Architecture, Governance, Multi-cloud |

---

## ğŸ“Š Evaluation Rubric

Each response is scored on 5 dimensions (0-10):

1. **Technical Correctness** - Accuracy of technical content
2. **Depth of Understanding** - How deeply concepts are understood
3. **Practical Experience** - Evidence of hands-on work
4. **Communication Clarity** - How clearly ideas are articulated
5. **Confidence** - Appropriate confidence in delivery

---

## ğŸ”§ Configuration

### Databricks Setup

1. Create a Databricks workspace
2. Deploy Gemini 3 Pro and Gemini Flash models
3. Create serving endpoints
4. Generate an access token

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `DATABRICKS_HOST` | Workspace URL | Required |
| `DATABRICKS_TOKEN` | Access token | Required |
| `WHISPER_MODEL` | STT model size | `large-v3` |
| `TTS_MODEL` | TTS engine | `edge-tts` |
| `MAX_QUESTIONS` | Questions per interview | `10` |

---

## ğŸš¢ Deployment

### Databricks Apps (Recommended)

Deploy directly to your Databricks workspace:

1. **Navigate to Apps in Databricks**
   - Go to your Databricks workspace
   - Click on **Compute** â†’ **Apps**
   - Click **Create App**

2. **Configure the App**
   - Name: `dataready-io`
   - Source: Connect your GitHub repository or upload files
   - The `app.yaml` configuration will be auto-detected

3. **Set Environment Variables (Secrets)**
   
   In the Databricks Apps UI, configure these secrets:
   
   | Variable | Description |
   |----------|-------------|
   | `DATABRICKS_HOST` | Your Databricks workspace URL |
   | `DATABRICKS_TOKEN` | Personal Access Token |
   | `GEMINI_PRO_ENDPOINT` | Gemini Pro model endpoint |
   | `GEMINI_FLASH_ENDPOINT` | Gemini Flash model endpoint |

4. **Deploy**
   - Click **Deploy** and wait for the app to start
   - Access via the provided Databricks App URL

### Railway

1. Connect your GitHub repository to Railway
2. Add environment variables in Railway dashboard:
   - `DATABRICKS_HOST`
   - `DATABRICKS_TOKEN`
   - `GEMINI_PRO_ENDPOINT`
   - `GEMINI_FLASH_ENDPOINT`
3. Deploy! Railway will auto-detect the Dockerfile

### Manual Docker Deployment

```bash
# Build
docker build -t dataready .

# Run with environment variables
docker run -d -p 8000:8000 \
  -e DATABRICKS_HOST="your-host" \
  -e DATABRICKS_TOKEN="your-token" \
  -e GEMINI_PRO_ENDPOINT="your-endpoint" \
  -e GEMINI_FLASH_ENDPOINT="your-endpoint" \
  dataready
```

---

## ğŸ›£ï¸ Roadmap

### Phase 1 (Current)
- [x] Core interview flow
- [x] AI question generation
- [x] Audio processing
- [x] Report generation

### Phase 2
- [ ] User authentication
- [ ] Interview history
- [ ] Question bank management
- [ ] Admin dashboard

### Phase 3
- [ ] Coding challenges
- [ ] Resume-based personalization
- [ ] Video recording playback
- [ ] Team/organization features

### Phase 4
- [ ] Mobile app
- [ ] API for integrations
- [ ] White-label options

---

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines before submitting PRs.

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- Gemini models via Databricks
- OpenAI Whisper for transcription
- Edge-TTS for voice synthesis

---

<p align="center">
  <strong>Practice makes perfect. ğŸš€</strong>
</p>
